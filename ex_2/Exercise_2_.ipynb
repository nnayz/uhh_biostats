{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBdrxX7fIvPL"
      },
      "source": [
        "#Prequisites\n",
        "Please install Python and required libraries for this exercise, or do it in google colab.\n",
        "\n",
        "We recommend that you use either [PyTorch](https://pytorch.org/get-started/locally/) or [TensorFlow](https://www.tensorflow.org/learn)\n",
        "\n",
        "The import statements of the solution we prepared are specified below, however feel free to use any other library.\n",
        "\n",
        "\n",
        "## Data\n",
        "The data is gained from sequencing data of the microbiome in humans colon. Basically different DNA fragments can be matched to the same species due to high variety of bacterial DNA, so starting from sequencing data of the complete mix of bacterial species from the colon, different fragments are matched to species Pan-genomes to identify different species.\n",
        "In the processing, the sequences were mapped to bacteria species and normalized such that , these values describe a normalized quantitative measure.\n",
        "Additionally, the following columns are provided:\n",
        "- the first column is just an index generated in pseudoanonymization\n",
        "- health status: 0 is healthy, 1 is colorectal cancer\n",
        "- gender: 0 is female, 1 is male\n",
        "- bmi is the body mass index\n",
        "- age is, well, age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KaMKWFGjOWN"
      },
      "outputs": [],
      "source": [
        "# We used these packages for our solution, you might use others\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Sequential\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkqGondsrcH2"
      },
      "source": [
        "#1)\n",
        "Read in the data and perform any cleaning you find necessary. You don't have to do any normalization. (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KM7Jm6o8rcH2"
      },
      "outputs": [],
      "source": [
        "# Read the data\n",
        "\n",
        "# Do any data cleaning you feel is necessary (data is normalized already)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TW5ifb3KJDI"
      },
      "source": [
        "# 2)\n",
        "Prepare two heatmaps of the data, one of health_status = 0, the other of health_status = 1. (2 points)\n",
        "\n",
        "You don't have to worry about the column_names overlapping, we just want a quick overview."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UovATrWMoOPx",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# prepare the two heatmaps."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3)\n",
        "Plot the sample elements based on their bacteria abundances with PCA. (3 points)"
      ],
      "metadata": {
        "id": "poprJEecVyzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "p_CR00dpWCqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB4euiyELR_b"
      },
      "source": [
        "#4)\n",
        "Train a MLP(Multilayer Perceptron) on the data to classify the health_status based on the given variables/features. We provide you the main part of the implementation.\n",
        "\n",
        "Your task is to calculate and print the training and testing losses and accuracies over the epochs.\n",
        "\n",
        "(4 points)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kybIZsIercH3"
      },
      "outputs": [],
      "source": [
        "# Extract features and target labels\n",
        "X = df.drop('health_status', axis=1).values\n",
        "y = df['health_status'].values\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# Split the data into training and testing sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=9)\n",
        "\n",
        "# Define the neural network\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(437, 50),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(50, 50),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(50, 2),\n",
        "    nn.Softmax(dim=1)  # Specify the dimension for softmax\n",
        ")\n",
        "\n",
        "# Define loss criterion and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 1000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate training accuracy\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        _, predicted_train = torch.max(outputs, 1)\n",
        "        # Your code - calculate training accuracy\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        test_outputs = model(X_test)\n",
        "        _, predicted_test = torch.max(test_outputs, 1)\n",
        "        # Your code - calculate test accuracy\n",
        "\n",
        "    if (epoch+1) % 100 == 0:\n",
        "        # Your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uJJgPnLrcH4"
      },
      "source": [
        "#5)\n",
        "Calculate the accuracy and AUC for the test set. Also plot the ROC (3 points)\n",
        "\n",
        "Your model should have around 60% or more accuracy. In some random splits you might get lower results, for this exercise just rerun the training in that case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fae5PMfXrcH4"
      },
      "outputs": [],
      "source": [
        "# Calculate performance metrics here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUQ2TtztAeei"
      },
      "source": [
        "#6)\n",
        "Train a logistic regression classifier using the same data split and evaluation approach. Compare the performance of both models. (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TaxTXUKGoYh"
      },
      "outputs": [],
      "source": [
        "# Train the logistic regression classifier here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kcHUBDCG0KY"
      },
      "outputs": [],
      "source": [
        "# Evaluate the logistic regression classifier here and compare to MLP"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}